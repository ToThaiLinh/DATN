{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4d5d82f-8800-4614-80ee-4759c23d2f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "# import boto3\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e170771-b336-488c-990e-5a2afbcc00db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "com.mysql#mysql-connector-j added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-82632530-92d7-468b-b7fc-8228b085e456;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.mysql#mysql-connector-j;8.0.33 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.21.9 in central\n",
      ":: resolution report :: resolve 153ms :: artifacts dl 5ms\n",
      "\t:: modules in use:\n",
      "\tcom.google.protobuf#protobuf-java;3.21.9 from central in [default]\n",
      "\tcom.mysql#mysql-connector-j;8.0.33 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-82632530-92d7-468b-b7fc-8228b085e456\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/5ms)\n",
      "26/01/18 01:31:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/01/18 01:31:19 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Define the package coordinates\n",
    "mysql_jar_package = \"com.mysql:mysql-connector-j:8.0.33\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"olist_order_items_dataset\") \\\n",
    "    .config(\"spark.cores.max\", \"1\") \\\n",
    "    .config(\"spark.executor.memory\", \"2g\") \\\n",
    "    .config(\"spark.jars.packages\", mysql_jar_package) \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bd0ae6b-ad95-4526-b216-f008a62bbfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- customer_unique_id: string (nullable = true)\n",
      " |-- customer_zip_code_prefix: string (nullable = true)\n",
      " |-- customer_city: string (nullable = true)\n",
      " |-- customer_state: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/17 20:29:16 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------------------+--------------------+--------------+\n",
      "|         customer_id|  customer_unique_id|customer_zip_code_prefix|       customer_city|customer_state|\n",
      "+--------------------+--------------------+------------------------+--------------------+--------------+\n",
      "|06b8999e2fba1a1fb...|861eff4711a542e4b...|                   14409|              franca|            SP|\n",
      "|18955e83d337fd6b2...|290c77bc529b7ac93...|                   09790|sao bernardo do c...|            SP|\n",
      "|4e7b3e00288586ebd...|060e732b5b29e8181...|                   01151|           sao paulo|            SP|\n",
      "|b2b6027bc5c5109e5...|259dac757896d24d7...|                   08775|     mogi das cruzes|            SP|\n",
      "|4f2d8ab171c80ec83...|345ecd01c38d18a90...|                   13056|            campinas|            SP|\n",
      "+--------------------+--------------------+------------------------+--------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = '../dataset/olist_order_items_dataset.csv'\n",
    "df = spark.read \\\n",
    "    .format('csv') \\\n",
    "    .option('header', 'true') \\\n",
    "    .option('inferSchema', 'false') \\\n",
    "    .option(\"escape\", '\"') \\\n",
    "    .option(\"quote\", '\"') \\\n",
    "    .option(\"multiLine\", \"true\") \\\n",
    "    .option(\"ignoreLeadingWhiteSpace\", \"true\") \\\n",
    "    .option(\"ignoreTrailingWhiteSpace\", \"true\") \\\n",
    "    .load(file)\n",
    "# df.printSchema()\n",
    "# df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5a44827-be2a-4658-af02-9e3ec6f1cf30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# MySQL connection properties\n",
    "jdbc_url = \"jdbc:mysql://mariadb:3306/database_raw\"\n",
    "db_properties = {\n",
    "    \"user\": \"admin\",\n",
    "    \"password\": \"admin\",\n",
    "    \"driver\": \"com.mysql.cj.jdbc.Driver\" # Use \"com.mysql.jdbc.Driver\" for older connectors\n",
    "}\n",
    "table_name = \"olist_order_items_dataset\"\n",
    "\n",
    "# Write the DataFrame to the MySQL table\n",
    "df.write.jdbc(url=jdbc_url, table=table_name, mode=\"append\", properties=db_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d12d74b-ed99-46b9-997d-e8b9643350ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0140ef-14b5-4a48-9b2e-2aea088cb4c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
