version: "3.9"

services:
  minio:
    image: "minio/minio:RELEASE.2025-09-07T16-13-09Z"
    container_name: minio
    hostname: minio
    ports:
      - "9001:9001"
      - "9000:9000"
    command: ["server", "/data", "--console-address", ":9001"]
    volumes:
      - ./minio/data:/data
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin
      - MINIO_DOMAIN=minio
    networks:
      data_network:
        aliases:
          - warehouse.minio

  mc:
    image: minio/mc
    container_name: mc
    hostname: mc
    environment:
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
      - AWS_REGION=us-east-1
    entrypoint: |
      /bin/sh -c "
      until (/usr/bin/mc alias set minio http://minio:9000 minioadmin minioadmin) do echo '...waiting...' && sleep 1; done;
      /usr/bin/mc mb --ignore-existing minio/warehouse;
      /usr/bin/mc policy set public minio/warehouse;
      tail -f /dev/null
      "
    depends_on:
      - minio
    networks:
      - data_network

  mariadb:
    image: mariadb:10.5.8
    container_name: mariadb
    hostname: mariadb
    ports:
      - 3306:3306
    environment:
      MYSQL_ROOT_PASSWORD: admin
      MYSQL_USER: admin
      MYSQL_PASSWORD: admin
      MYSQL_DATABASE: database_raw
    volumes:
      - ./mariadb/data:/var/lib/mysql
    networks:
      - data_network

  postgres:
    image: postgres:14.19-alpine3.21
    container_name: postgres
    hostname: postgres
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: metastore_db
    ports:
      - "5432:5432"
    volumes:
      - ./postgres/data:/var/lib/postgresql/data
    networks:
      - data_network

  hive-metastore:
    image: "thailinh2003/hive-metastore-postgresql:v1"
    container_name: hive-metastore
    hostname: hive-metastore
    ports:
      - "9083:9083" # Metastore Thrift
    volumes:
      - ./hive-metastore/conf/metastore-site.xml:/opt/apache-hive-metastore-3.0.0-bin/conf/metastore-site.xml:ro
    environment:
      METASTORE_DB_HOSTNAME: postgres
    depends_on:
      - postgres
    networks:
      - data_network

  # hive-metastore:
  #   image: "bitsondatadev/hive-metastore:latest"
  #   container_name: hive-metastore
  #   hostname: hive-metastore
  #   ports:
  #     - "9083:9083" # Metastore Thrift
  #   volumes:
  #     - ./hive-metastore/conf/metastore-site-mariadb.xml:/opt/apache-hive-metastore-3.0.0-bin/conf/metastore-site.xml:ro
  #   environment:
  #     METASTORE_DB_HOSTNAME: mariadb
  #   depends_on:
  #     - mariadb
  #   networks:
  #     - data_network

  # spark-iceberg:
  #   image: tabulario/spark-iceberg
  #   container_name: spark-iceberg
  #   networks:
  #     - data_network
  #   depends_on:
  #     - hive-metastore
  #     - minio
  #   volumes:
  #     - ./minio/data/warehouse:/home/iceberg/warehouse
  #     - ./jupyter-notebook/notebooks:/home/iceberg/notebooks/notebooks
  #   environment:
  #     - AWS_ACCESS_KEY_ID=minioadmin
  #     - AWS_SECRET_ACCESS_KEY=minioadmin
  #     - AWS_REGION=us-east-1
  #   ports:
  #     - 8888:8888
  #     - 8081:8080
  #     - 10000:10000
  #     - 10001:10001

  jupyter:
    # image: thailinh2003/jupyter-pyspark-3.5.7_1.9.0:v1
    image: thailinh2003/jupyter-spark:4.0.0
    container_name: jupyter
    hostname: jupyter
    ports:
      - "8888:8888"
      - "4040:4040"
    environment:
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
      - AWS_REGION=us-east-1
    volumes:
      - ./jupyter-notebook/notebooks:/home/iceberg/notebooks/
    depends_on:
      - hive-metastore
      - minio
    command: >
      /bin/sh -c "/usr/local/bin/jupyter-lab \
      --notebook-dir=/home/iceberg/notebooks \
      --ip=* \
      --LabApp.token= \
      --LabApp.password= \
      --no-browser \
      --allow-root"
    networks:
      - data_network

  trino:
    image: trinodb/trino:478
    container_name: trino
    hostname: trino
    ports:
      - "8090:8080"
    environment:
      - TRINO_JVM_OPTS=-Xmx1G
    volumes:
      - ./trino/etc/catalog:/etc/trino/catalog:ro
    depends_on:
      - hive-metastore
      - minio
    networks:
      - data_network

  spark-master:
    image: thailinh2003/spark:3.0.0
    container_name: spark-master
    hostname: spark-master
    command:
      [
        "/opt/spark/bin/spark-class",
        "org.apache.spark.deploy.master.Master",
        "--host",
        "spark-master",
        "--port",
        "7077",
        "--webui-port",
        "8088",
      ]
    volumes:
      - ./spark/jmx-config.yaml:/opt/jmx/config.yaml
      - ./spark/jars/jmx_prometheus_javaagent-0.16.1.jar:/opt/jmx/jmx_prometheus_javaagent.jar
    environment:
      SPARK_MASTER_HOST: spark-master
      SPARK_MASTER_PORT: 7077
      SPARK_MASTER_WEBUI_PORT: 8088
      SPARK_NO_DAEMONIZE: true
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin
      AWS_REGION: us-east-1
      SPARK_DAEMON_JAVA_OPTS: >
        -javaagent:/opt/jmx/jmx_prometheus_javaagent.jar=7071:/opt/jmx/config.yaml
    ports:
      - "7077:7077" # Spark Master port
      - "7071:7071"
      - "8088:8088" # Spark Master Web UI (avoiding 8080 which Airflow uses)
    networks:
      - data_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8088"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Spark Worker
  spark-worker:
    image: thailinh2003/spark:3.0.0
    container_name: spark-worker
    hostname: spark-worker
    command:
      [
        "/opt/spark/bin/spark-class",
        "org.apache.spark.deploy.worker.Worker",
        "spark://spark-master:7077",
      ]
    depends_on:
      spark-master:
        condition: service_healthy
    environment:
      SPARK_WORKER_CORES: 4
      SPARK_WORKER_MEMORY: 4g
      SPARK_WORKER_PORT: 8881
      SPARK_WORKER_WEBUI_PORT: 8089
      SPARK_NO_DAEMONIZE: true
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin
      AWS_REGION: us-east-1
    ports:
      - "8089:8089" # Spark Worker Web UI
    networks:
      - data_network

  # spark-iceberg:
  #   image: anhbtsi/spark-jupyterhub:3.5.9
  #   container_name: spark-iceberg
  #   volumes:
  #     - ./warehouse:/home/iceberg/warehouse
  #     - ./notebooks:/home/iceberg/notebooks/notebooks
  #   environment:
  #     - AWS_SECRET_ACCESS_KEY=minioadmin
  #     - AWS_ACCESS_KEY_ID=minioadmin
  #     - AWS_REGION=us-east-1
  #     - SPARK_CLUSTER=MASTER
  #   ports:
  #     - 8008:8080
  #     # - 7077:7077
  #   networks:
  #     - data_network

  superset:
    # build:
    #   context: ./superset
    #   dockerfile: Dockerfile
    image: thailinh2003/superset:v1
    container_name: superset
    hostname: superset
    environment:
      - SUPERSET_ENV=production
      - ADMIN_USERNAME=admin
      - ADMIN_EMAIL=admin@superset.com
      - ADMIN_PASSWORD=admin
    depends_on:
      - postgres
      - trino
    ports:
      - "8386:8088"
    networks:
      - data_network

  # Airflow
  airflow-webserver:
    image: thailinh2003/airflow:7.0.0
    container_name: airflow-webserver
    hostname: airflow-webserver
    restart: always
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:postgres@postgres/airflow
      - AIRFLOW__WEBSERVER__SECRET_KEY=tothailinh2003
      - AIRFLOW__CORE__FERNET_KEY=GgyJ5jUehSy2zQqY958eUWW1ezEgNp4OerBy-AKuD14=
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
      - AWS_REGION=us-east-1
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/great_expectations:/opt/airflow/great_expectations
    ports:
      - "8080:8080"
      - "8000:8000"
    depends_on:
      - postgres
    # entrypoint: /entrypoint.sh
    command: webserver
    networks:
      - data_network

  airflow-scheduler:
    image: thailinh2003/airflow:7.0.0
    container_name: airflow-scheduler
    hostname: airflow-scheduler
    restart: always
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:postgres@postgres/airflow
      - AIRFLOW__WEBSERVER__SECRET_KEY=tothailinh2003
      - AIRFLOW__CORE__FERNET_KEY=GgyJ5jUehSy2zQqY958eUWW1ezEgNp4OerBy-AKuD14=
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
      - AWS_REGION=us-east-1
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/great_expectations:/opt/airflow/great_expectations
    # ports:
    #   - "8793:8793"
    depends_on:
      - postgres
    # entrypoint: /entrypoint.sh
    command: scheduler
    networks:
      - data_network

  kafka1:
    image: "apache/kafka:3.9.1"
    hostname: kafka1
    container_name: kafka1
    volumes:
      - ./kafka/kafka1/data:/var/lib/kafka/data
    user: root
    ports:
      - "9092:9092"
    environment:
      - KAFKA_ENABLE_KRAFT=yes
      - KAFKA_PROCESS_ROLES=broker,controller
      - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka1:9092
      - KAFKA_BROKER_ID=1
      - KAFKA_KRAFT_CLUSTER_ID=LelM2dIFQkiUFvXCEcqRWA
      - KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka1:9093
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_LOG_DIRS=/var/lib/kafka/data
    networks:
      - data_network

  # kafka2:
  #   image: "bitnami/kafka:3.9.1"
  #   hostname: kafka2
  #   container_name: kafka2
  #   volumes:
  #     - ./kafka/kafka2/data:/var/lib/kafka/data
  #   user: root
  #   ports:
  #     - "9094:9094"
  #   environment:
  #     - KAFKA_ENABLE_KRAFT=yes
  #     - KAFKA_PROCESS_ROLES=broker,controller
  #     - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER
  #     - KAFKA_LISTENERS=PLAINTEXT://:9094,CONTROLLER://:9095
  #     - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
  #     - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka2:9094
  #     - KAFKA_BROKER_ID=2
  #     - KAFKA_KRAFT_CLUSTER_ID=LelM2dIFQkiUFvXCEcqRWA
  #     - KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka1:9093;2@kafka2:9095;3@kafka3:9097
  #     - ALLOW_PLAINTEXT_LISTENER=yes
  #     - KAFKA_LOG_DIRS=/var/lib/kafka/data
  #   networks:
  #     - data_network

  # kafka3:
  #   image: "bitnami/kafka:3.9.1"
  #   hostname: kafka3
  #   container_name: kafka3
  #   volumes:
  #     - ./kafka/kafka3/data:/var/lib/kafka/data
  #   user: root
  #   ports:
  #     - "9096:9096"
  #   environment:
  #     - KAFKA_ENABLE_KRAFT=yes
  #     - KAFKA_PROCESS_ROLES=broker,controller
  #     - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER
  #     - KAFKA_LISTENERS=PLAINTEXT://:9096,CONTROLLER://:9097
  #     - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
  #     - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka3:9096
  #     - KAFKA_BROKER_ID=3
  #     - KAFKA_KRAFT_CLUSTER_ID=LelM2dIFQkiUFvXCEcqRWA
  #     - KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka1:9093;2@kafka2:9095;3@kafka3:9097
  #     - ALLOW_PLAINTEXT_LISTENER=yes
  #     - KAFKA_LOG_DIRS=/var/lib/kafka/data
  #   networks:
  #     - data_network

  kafbat-ui:
    container_name: kafbat-ui
    hostname: kafbat-ui
    image: ghcr.io/kafbat/kafka-ui:latest
    ports:
      - 8081:8080
    environment:
      # DYNAMIC_CONFIG_ENABLED: "true"
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka1:9092
      KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL: PLAINTEXT
    # volumes:
    #   - ./kafbat-ui/config.yml:/etc/kafkaui/dynamic_config.yaml
    networks:
      - data_network
  grafana:
    image: grafana/grafana:12.3
    container_name: grafana
    hostname: grafana
    restart: unless-stopped
    ports:
      - 3000:3000
    env_file:
      - ./grafana/login_config
    volumes:
      - ./grafana/grafana_db:/var/lib/grafana:rw #needs command 'sudo chmod -R 777 Grafana/*'
      - ./grafana/provisioning/datasource:/etc/grafana/provisioning/datasources
      - ./grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards
    depends_on:
      - prometheus
    networks:
      - data_network

    # Prometheus Service
  prometheus:
    image: prom/prometheus:v2.20.1
    container_name: prometheus
    hostname: prometheus
    restart: unless-stopped
    ports:
      - 9090:9090
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus/data"
      - "--storage.tsdb.retention.time=15d"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./prometheus/prometheus_db:/prometheus/data:rw #needs command 'sudo chmod -R 777 Prometheus/prometheus_db'
    depends_on:
      - node-exporter
    networks:
      - data_network

  # Node-Exporter Service
  node-exporter:
    image: prom/node-exporter:v1.0.1
    container_name: node-exporter
    hostname: node-exporter
    ports:
      - 9100:9100
    restart: unless-stopped
    networks:
      - data_network

networks:
  data_network:
    name: data_network
    driver: bridge
